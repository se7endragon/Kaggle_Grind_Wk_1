{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dataset\n",
    "df_train = pd.read_csv(\"train.csv\")\n",
    "df_test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# 미스터, 미세스 만 빼버리기\n",
    "df_train['Name'] = df_train['Name'].str.split(',').str[1].str.split('.').str[0]\n",
    "non_name = ~df_train['Name'].isin([' Mr',' Miss',' Mrs',' Master'])\n",
    "df_train.loc[non_name,'Name'] = df_train.loc[non_name,'Sex'].apply(lambda x:' Mr' if x == 'male' else ' Miss')\n",
    "le3 = preprocessing.LabelEncoder()\n",
    "le3.fit(df_train['Name'])\n",
    "df_train['Name'] = le3.transform(df_train['Name'])\n",
    "\n",
    "#결측치 처리 (Age, Embarked)\n",
    "df_train['Age'].fillna(df_train['Age'].mean(),inplace=True)\n",
    "df_test['Age'].fillna(df_train['Age'].mean(),inplace=True)\n",
    "df_train['Embarked'].fillna('C',inplace=True)\n",
    "\n",
    "#Cabin 결측치 처리 겸 변수 변환\n",
    "#df_train['Cabin'] = df_train.Cabin.apply(lambda x: 1 if pd.notnull(x) else 0)\n",
    "#df_test['Cabin'] = df_test.Cabin.apply(lambda x: 1 if pd.notnull(x) else 0)\n",
    "df_train['Cabin_alpha'] = df_train[df_train['Cabin'].isnull()==False]['Cabin'].map(lambda x: x[0])\n",
    "df_train['Cabin_alpha'].fillna(\"N\",inplace=True)\n",
    "\n",
    "#Group 변수 생성\n",
    "#Family size랑 dup_count 중 큰걸로 fare 나누기.\n",
    "df_train['Family_size'] = df_train['SibSp']+df_train['Parch']+1\n",
    "df_train['dup_count'] = df_train.groupby(['Ticket'])['Ticket'].transform('count')\n",
    "df_train['Group'] = ~((df_train['Family_size'] == 1) & (df_train['dup_count'] == 1))\n",
    "df_train['Group_count'] = df_train[['Family_size','dup_count']].max(axis=1)\n",
    "df_train['Fare_ind'] = df_train['Fare']/df_train['Group_count']\n",
    "\n",
    "#Fare 결측치 처리 in test\n",
    "df_test['Fare'].fillna(df_test['Fare'].mean(),inplace=True)\n",
    "\n",
    "df_test['Family_size'] = df_test['SibSp']+df_test['Parch']+1\n",
    "df_test['dup_count'] = df_test.groupby(['Ticket'])['Ticket'].transform('count')\n",
    "df_test['Group'] = ~((df_test['Family_size'] == 1) & (df_test['dup_count'] == 1))\n",
    "df_test['Group_count'] = df_test[['Family_size','dup_count']].max(axis=1)\n",
    "df_test['Fare_ind'] = df_test['Fare']/df_test['Group_count']\n",
    "\n",
    "# Categorical Feature Encoding\n",
    "le = preprocessing.LabelEncoder()\n",
    "le2 = preprocessing.LabelEncoder()\n",
    "le.fit(df_train['Embarked'])\n",
    "le2.fit(df_train['Cabin_alpha'])\n",
    "df_train['Embarked']=le.transform(df_train['Embarked'])\n",
    "df_train['Cabin_alpha']=le2.transform(df_train['Cabin_alpha'])\n",
    "df_train['Noyak'] = df_train.apply(lambda x: 0 if x['Age'] < 7 or x['Sex'] == 'female' else 1, axis=1)\n",
    "df_train['Sex'] = df_train['Sex'].apply(lambda x: 1 if x == 'male' else 0)\n",
    "df_test['Sex'] = df_test['Sex'].apply(lambda x: 1 if x == 'male' else 0)\n",
    "\n",
    "#df_train = pd.get_dummies(df_train, columns = ['Embarked'],drop_first=True,prefix='', prefix_sep='')\n",
    "#df_test = pd.get_dummies(df_test, columns = ['Embarked'],drop_first=True,prefix='', prefix_sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    537\n",
       "1    189\n",
       "3    125\n",
       "0     40\n",
       "Name: Name, dtype: int64"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.Name.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델에 사용하지 않을 변수 제거\n",
    "train_X = df_train.drop(['PassengerId','SibSp','Parch','Survived','Cabin','Ticket','Fare','Family_size','dup_count'],axis=1)\n",
    "test_X = df_test.drop(['PassengerId','Name','Ticket','Fare','Cabin','Family_size','dup_count','Group_count'],axis=1)\n",
    "train_y = df_train.Survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Embarked',\n",
       "       'Cabin_alpha', 'Group', 'Group_count', 'Fare_ind', 'Noyak'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "                   estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                           colsample_bylevel=1,\n",
       "                                           colsample_bytree=1, gamma=0,\n",
       "                                           learning_rate=0.1, max_delta_step=0,\n",
       "                                           max_depth=3, min_child_weight=1,\n",
       "                                           missing=None, n_estimators=400,\n",
       "                                           n_jobs=1, nthread=None,\n",
       "                                           objective='binary:logistic',\n",
       "                                           random_seed=0, random_state=0,\n",
       "                                           reg_alpha=0, reg_...\n",
       "                                           silent=True, subsample=1),\n",
       "                   iid='warn', n_iter=100, n_jobs=None,\n",
       "                   param_distributions={'colsample_bytree': [0.6, 0.8, 1.0],\n",
       "                                        'gamma': [0.5, 1, 1.5, 2, 5],\n",
       "                                        'learning_rate': [0.0001, 0.001, 0.01,\n",
       "                                                          0.1],\n",
       "                                        'max_depth': [3, 4, 5],\n",
       "                                        'min_child_weight': [1, 5, 10],\n",
       "                                        'subsample': [0.6, 0.8, 1.0]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=0, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg = xgb.XGBClassifier(random_seed=0,n_estimators=400)\n",
    "parameters = {\n",
    "        'min_child_weight': [1, 5, 10],\n",
    "        'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "        'max_depth': [3, 4, 5],\n",
    "        'learning_rate': [0.0001, 0.001, 0.01, 0.1]\n",
    "        }\n",
    "clf = RandomizedSearchCV(xg, parameters,n_iter=100, cv=5,random_state=0)\n",
    "clf.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8451178451178452"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bytree=0.8, gamma=0.5, learning_rate=0.1,\n",
       "              max_delta_step=0, max_depth=5, min_child_weight=1, missing=None,\n",
       "              n_estimators=400, n_jobs=1, nthread=None,\n",
       "              objective='binary:logistic', random_seed=0, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "              silent=True, subsample=1)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgc = xgb.XGBClassifier(random_seed=0,n_estimators=400,subsample=1,min_child_weight=1,max_depth=5,learning_rate=0.1,gamma=0.5,colsample_bytree=0.8)\n",
    "xgc.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a1d02fe80>"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from xgboost import plot_importance\n",
    "plot_importance(xgc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method ClassifierMixin.score of XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bytree=0.8, gamma=0.5, learning_rate=0.1,\n",
       "              max_delta_step=0, max_depth=5, min_child_weight=1, missing=None,\n",
       "              n_estimators=400, n_jobs=1, nthread=None,\n",
       "              objective='binary:logistic', random_seed=0, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "              silent=True, subsample=1)>"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgc.score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Cabin_alpha</th>\n",
       "      <th>Group</th>\n",
       "      <th>Group_count</th>\n",
       "      <th>Fare_ind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>3.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>35.641650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>7.925000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>26.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>8.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>8.458300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>51.862500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>4.215000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>3.711100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>15.035400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>5.566667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>26.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>8.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "      <td>4.467857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>7.854200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "      <td>4.854167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>7.225000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>8.029200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>35.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>4.215000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "      <td>4.483929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>7.225000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "      <td>43.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>7.879200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>7.895800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>5.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>25.929200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "      <td>6.322727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>6.929150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>50.495800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>9.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>3.711100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>7.895800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>17.518067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>7.225000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>4.922900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>7.895800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>7.895800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>41.579150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>7.895800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>10.516700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>10.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>7.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "      <td>4.854167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>30.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>5.862500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>30.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>7.750000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass  Name  Sex  Age  Embarked  Cabin_alpha  Group  Group_count  \\\n",
       "0         3     2    1    1         2            7   True            2   \n",
       "1         1     3    0    1         0            2   True            2   \n",
       "2         3     1    0    1         2            7  False            1   \n",
       "3         1     3    0    1         2            2   True            2   \n",
       "4         3     2    1    1         2            7  False            1   \n",
       "5         3     2    1    1         1            7  False            1   \n",
       "6         1     2    1    0         2            4  False            1   \n",
       "7         3     0    1    0         2            7   True            5   \n",
       "8         3     3    0    1         2            7   True            3   \n",
       "9         2     3    0    0         0            7   True            2   \n",
       "10        3     1    0    0         2            6   True            3   \n",
       "11        1     1    0    0         2            2  False            1   \n",
       "12        3     2    1    1         2            7  False            1   \n",
       "13        3     2    1    1         2            7   True            7   \n",
       "14        3     1    0    0         2            7  False            1   \n",
       "15        2     3    0    0         2            7  False            1   \n",
       "16        3     0    1    0         1            7   True            6   \n",
       "17        2     2    1    1         2            7  False            1   \n",
       "18        3     3    0    1         2            7   True            2   \n",
       "19        3     3    0    1         0            7  False            1   \n",
       "20        2     2    1    1         2            7   True            2   \n",
       "21        2     2    1    1         2            3  False            1   \n",
       "22        3     1    0    0         1            7  False            1   \n",
       "23        1     2    1    1         2            0  False            1   \n",
       "24        3     1    0    0         2            7   True            5   \n",
       "25        3     3    0    1         2            7   True            7   \n",
       "26        3     2    1    1         0            7  False            1   \n",
       "27        1     2    1    1         2            2   True            6   \n",
       "28        3     1    0    1         1            7  False            1   \n",
       "29        3     2    1    1         2            7  False            1   \n",
       "..      ...   ...  ...  ...       ...          ...    ...          ...   \n",
       "861       2     2    1    1         2            7   True            2   \n",
       "862       1     3    0    1         2            3  False            1   \n",
       "863       3     1    0    1         2            7   True           11   \n",
       "864       2     2    1    1         2            7  False            1   \n",
       "865       2     3    0    1         2            7  False            1   \n",
       "866       2     1    0    1         0            7   True            2   \n",
       "867       1     2    1    1         2            0  False            1   \n",
       "868       3     2    1    1         2            7  False            1   \n",
       "869       3     0    1    0         2            7   True            3   \n",
       "870       3     2    1    1         2            7  False            1   \n",
       "871       1     3    0    1         2            3   True            3   \n",
       "872       1     2    1    1         2            1  False            1   \n",
       "873       3     2    1    1         2            7  False            1   \n",
       "874       2     3    0    1         0            7   True            2   \n",
       "875       3     1    0    0         0            7  False            1   \n",
       "876       3     2    1    1         2            7   True            2   \n",
       "877       3     2    1    1         2            7  False            1   \n",
       "878       3     2    1    1         2            7  False            1   \n",
       "879       1     3    0    0         0            2   True            2   \n",
       "880       2     3    0    1         2            7   True            2   \n",
       "881       3     2    1    1         2            7  False            1   \n",
       "882       3     1    0    1         2            7  False            1   \n",
       "883       2     2    1    1         2            7  False            1   \n",
       "884       3     2    1    1         2            7  False            1   \n",
       "885       3     3    0    1         1            7   True            6   \n",
       "886       2     2    1    1         2            7  False            1   \n",
       "887       1     1    0    1         2            1  False            1   \n",
       "888       3     1    0    1         2            7   True            4   \n",
       "889       1     2    1    1         0            2  False            1   \n",
       "890       3     2    1    1         1            7  False            1   \n",
       "\n",
       "      Fare_ind  \n",
       "0     3.625000  \n",
       "1    35.641650  \n",
       "2     7.925000  \n",
       "3    26.550000  \n",
       "4     8.050000  \n",
       "5     8.458300  \n",
       "6    51.862500  \n",
       "7     4.215000  \n",
       "8     3.711100  \n",
       "9    15.035400  \n",
       "10    5.566667  \n",
       "11   26.550000  \n",
       "12    8.050000  \n",
       "13    4.467857  \n",
       "14    7.854200  \n",
       "15   16.000000  \n",
       "16    4.854167  \n",
       "17   13.000000  \n",
       "18    9.000000  \n",
       "19    7.225000  \n",
       "20   13.000000  \n",
       "21   13.000000  \n",
       "22    8.029200  \n",
       "23   35.500000  \n",
       "24    4.215000  \n",
       "25    4.483929  \n",
       "26    7.225000  \n",
       "27   43.833333  \n",
       "28    7.879200  \n",
       "29    7.895800  \n",
       "..         ...  \n",
       "861   5.750000  \n",
       "862  25.929200  \n",
       "863   6.322727  \n",
       "864  13.000000  \n",
       "865  13.000000  \n",
       "866   6.929150  \n",
       "867  50.495800  \n",
       "868   9.500000  \n",
       "869   3.711100  \n",
       "870   7.895800  \n",
       "871  17.518067  \n",
       "872   5.000000  \n",
       "873   9.000000  \n",
       "874  12.000000  \n",
       "875   7.225000  \n",
       "876   4.922900  \n",
       "877   7.895800  \n",
       "878   7.895800  \n",
       "879  41.579150  \n",
       "880  13.000000  \n",
       "881   7.895800  \n",
       "882  10.516700  \n",
       "883  10.500000  \n",
       "884   7.050000  \n",
       "885   4.854167  \n",
       "886  13.000000  \n",
       "887  30.000000  \n",
       "888   5.862500  \n",
       "889  30.000000  \n",
       "890   7.750000  \n",
       "\n",
       "[891 rows x 9 columns]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean-Imputed Categorical Age Model\n",
    "train_X_2 =  train_X\n",
    "train_X_2['Age'] = train_X_2['Age'].apply(lambda x: 0 if x < 17 else(0 if x >49 else 1))\n",
    "train_X_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "                   estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                           colsample_bylevel=1,\n",
       "                                           colsample_bytree=1, gamma=0,\n",
       "                                           learning_rate=0.1, max_delta_step=0,\n",
       "                                           max_depth=3, min_child_weight=1,\n",
       "                                           missing=None, n_estimators=400,\n",
       "                                           n_jobs=1, nthread=None,\n",
       "                                           objective='binary:logistic',\n",
       "                                           random_seed=0, random_state=0,\n",
       "                                           reg_alpha=0, reg_...\n",
       "                                           silent=True, subsample=1),\n",
       "                   iid='warn', n_iter=100, n_jobs=None,\n",
       "                   param_distributions={'colsample_bytree': [0.6, 0.8, 1.0],\n",
       "                                        'gamma': [0.5, 1, 1.5, 2, 5],\n",
       "                                        'learning_rate': [0.0001, 0.001, 0.01,\n",
       "                                                          0.1],\n",
       "                                        'max_depth': [3, 4, 5],\n",
       "                                        'min_child_weight': [1, 5, 10],\n",
       "                                        'subsample': [0.6, 0.8, 1.0]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=0, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg = xgb.XGBClassifier(random_seed=0,n_estimators=400)\n",
    "parameters = {\n",
    "        'min_child_weight': [1, 5, 10],\n",
    "        'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "        'max_depth': [3, 4, 5],\n",
    "        'learning_rate': [0.0001, 0.001, 0.01, 0.1]\n",
    "        }\n",
    "clf = RandomizedSearchCV(xg, parameters,n_iter=100, cv=5,random_state=0)\n",
    "clf.fit(train_X_2, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'subsample': 0.8, 'min_child_weight': 1, 'max_depth': 5, 'learning_rate': 0.1, 'gamma': 1, 'colsample_bytree': 0.8}\n",
      "0.8372615039281706\n"
     ]
    }
   ],
   "source": [
    "print(clf.best_params_)\n",
    "print(clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['C85', 'C123', 'E46', 'G6', 'C103', 'D56', 'A6', 'C23 C25 C27',\n",
       "       'B78', 'D33', 'B30', 'C52', 'B28', 'C83', 'F33', 'F G73', 'E31',\n",
       "       'A5', 'D10 D12', 'D26', 'C110', 'B58 B60', 'E101', 'F E69', 'D47',\n",
       "       'B86', 'F2', 'C2', 'E33', 'B19', 'A7', 'C49', 'F4', 'A32', 'B4',\n",
       "       'B80', 'A31', 'D36', 'D15', 'C93', 'C78', 'D35', 'C87', 'B77',\n",
       "       'E67', 'B94', 'C125', 'C99', 'C118', 'D7', 'A19', 'B49', 'D',\n",
       "       'C22 C26', 'C106', 'C65', 'E36', 'C54', 'B57 B59 B63 B66', 'C7',\n",
       "       'E34', 'C32', 'B18', 'C124', 'C91', 'E40', 'T', 'C128', 'D37',\n",
       "       'B35', 'E50', 'C82', 'B96 B98', 'E10', 'E44', 'A34', 'C104',\n",
       "       'C111', 'C92', 'E38', 'D21', 'E12', 'E63', 'A14', 'B37', 'C30',\n",
       "       'D20', 'B79', 'E25', 'D46', 'B73', 'C95', 'B38', 'B39', 'B22',\n",
       "       'C86', 'C70', 'A16', 'C101', 'C68', 'A10', 'E68', 'B41', 'A20',\n",
       "       'D19', 'D50', 'D9', 'A23', 'B50', 'A26', 'D48', 'E58', 'C126',\n",
       "       'B71', 'B51 B53 B55', 'D49', 'B5', 'B20', 'F G63', 'C62 C64',\n",
       "       'E24', 'C90', 'C45', 'E8', 'B101', 'D45', 'C46', 'D30', 'E121',\n",
       "       'D11', 'E77', 'F38', 'B3', 'D6', 'B82 B84', 'D17', 'A36', 'B102',\n",
       "       'B69', 'E49', 'C47', 'D28', 'E17', 'A24', 'C50', 'B42', 'C148'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[~train['Cabin'].isnull()].Cabin.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    136\n",
       "0     80\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train['Pclass']==1].Survived.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Cabin_alpha</th>\n",
       "      <th>Family_size</th>\n",
       "      <th>dup_count</th>\n",
       "      <th>Group</th>\n",
       "      <th>Group_count</th>\n",
       "      <th>Fare_ind</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>447.016393</td>\n",
       "      <td>2.531876</td>\n",
       "      <td>0.852459</td>\n",
       "      <td>30.415100</td>\n",
       "      <td>0.553734</td>\n",
       "      <td>0.329690</td>\n",
       "      <td>22.117887</td>\n",
       "      <td>1.641166</td>\n",
       "      <td>6.426230</td>\n",
       "      <td>1.883424</td>\n",
       "      <td>1.746812</td>\n",
       "      <td>0.386157</td>\n",
       "      <td>2.021858</td>\n",
       "      <td>12.054411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>444.368421</td>\n",
       "      <td>1.950292</td>\n",
       "      <td>0.318713</td>\n",
       "      <td>28.549778</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.464912</td>\n",
       "      <td>48.395408</td>\n",
       "      <td>1.356725</td>\n",
       "      <td>5.175439</td>\n",
       "      <td>1.938596</td>\n",
       "      <td>1.853801</td>\n",
       "      <td>0.634503</td>\n",
       "      <td>2.233918</td>\n",
       "      <td>20.936435</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          PassengerId    Pclass       Sex        Age     SibSp     Parch  \\\n",
       "Survived                                                                   \n",
       "0          447.016393  2.531876  0.852459  30.415100  0.553734  0.329690   \n",
       "1          444.368421  1.950292  0.318713  28.549778  0.473684  0.464912   \n",
       "\n",
       "               Fare  Embarked  Cabin_alpha  Family_size  dup_count     Group  \\\n",
       "Survived                                                                       \n",
       "0         22.117887  1.641166     6.426230     1.883424   1.746812  0.386157   \n",
       "1         48.395408  1.356725     5.175439     1.938596   1.853801  0.634503   \n",
       "\n",
       "          Group_count   Fare_ind  \n",
       "Survived                          \n",
       "0            2.021858  12.054411  \n",
       "1            2.233918  20.936435  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.groupby(['Survived']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">PassengerId</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Survived</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Group_count</th>\n",
       "      <th colspan=\"8\" halign=\"left\">Fare_ind</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>...</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <th>Embarked</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">1</th>\n",
       "      <th>0</th>\n",
       "      <td>87.0</td>\n",
       "      <td>440.919540</td>\n",
       "      <td>243.405644</td>\n",
       "      <td>2.0</td>\n",
       "      <td>266.50</td>\n",
       "      <td>453.0</td>\n",
       "      <td>637.50</td>\n",
       "      <td>890.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0.701149</td>\n",
       "      <td>...</td>\n",
       "      <td>3.00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>45.409578</td>\n",
       "      <td>30.259151</td>\n",
       "      <td>14.850000</td>\n",
       "      <td>28.588550</td>\n",
       "      <td>37.758333</td>\n",
       "      <td>49.5042</td>\n",
       "      <td>170.77640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>329.500000</td>\n",
       "      <td>118.086832</td>\n",
       "      <td>246.0</td>\n",
       "      <td>287.75</td>\n",
       "      <td>329.5</td>\n",
       "      <td>371.25</td>\n",
       "      <td>413.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.75</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>37.500000</td>\n",
       "      <td>10.606602</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>33.750000</td>\n",
       "      <td>37.500000</td>\n",
       "      <td>41.2500</td>\n",
       "      <td>45.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>127.0</td>\n",
       "      <td>477.842520</td>\n",
       "      <td>249.989537</td>\n",
       "      <td>4.0</td>\n",
       "      <td>273.50</td>\n",
       "      <td>493.0</td>\n",
       "      <td>698.50</td>\n",
       "      <td>888.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>0.582677</td>\n",
       "      <td>...</td>\n",
       "      <td>3.00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>32.944412</td>\n",
       "      <td>21.158412</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.282300</td>\n",
       "      <td>28.500000</td>\n",
       "      <td>37.8875</td>\n",
       "      <td>221.77920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2</th>\n",
       "      <th>0</th>\n",
       "      <td>17.0</td>\n",
       "      <td>444.352941</td>\n",
       "      <td>297.394507</td>\n",
       "      <td>10.0</td>\n",
       "      <td>182.00</td>\n",
       "      <td>390.0</td>\n",
       "      <td>686.00</td>\n",
       "      <td>875.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>...</td>\n",
       "      <td>3.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>12.549366</td>\n",
       "      <td>2.185885</td>\n",
       "      <td>6.929150</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.334733</td>\n",
       "      <td>13.8625</td>\n",
       "      <td>15.05000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>181.248448</td>\n",
       "      <td>304.0</td>\n",
       "      <td>313.50</td>\n",
       "      <td>323.0</td>\n",
       "      <td>475.00</td>\n",
       "      <td>627.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.350000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.350000</td>\n",
       "      <td>12.350000</td>\n",
       "      <td>12.350000</td>\n",
       "      <td>12.3500</td>\n",
       "      <td>12.35000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>164.0</td>\n",
       "      <td>446.634146</td>\n",
       "      <td>248.088942</td>\n",
       "      <td>16.0</td>\n",
       "      <td>234.50</td>\n",
       "      <td>439.0</td>\n",
       "      <td>668.00</td>\n",
       "      <td>887.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>0.463415</td>\n",
       "      <td>...</td>\n",
       "      <td>3.00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>11.004243</td>\n",
       "      <td>3.675578</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.750000</td>\n",
       "      <td>12.587500</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>26.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">3</th>\n",
       "      <th>0</th>\n",
       "      <td>66.0</td>\n",
       "      <td>451.484848</td>\n",
       "      <td>277.967305</td>\n",
       "      <td>20.0</td>\n",
       "      <td>205.00</td>\n",
       "      <td>483.0</td>\n",
       "      <td>693.50</td>\n",
       "      <td>876.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.378788</td>\n",
       "      <td>...</td>\n",
       "      <td>2.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>6.717735</td>\n",
       "      <td>1.384601</td>\n",
       "      <td>2.409733</td>\n",
       "      <td>5.825012</td>\n",
       "      <td>7.227100</td>\n",
       "      <td>7.2292</td>\n",
       "      <td>9.39375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>72.0</td>\n",
       "      <td>420.347222</td>\n",
       "      <td>259.844545</td>\n",
       "      <td>6.0</td>\n",
       "      <td>198.50</td>\n",
       "      <td>400.5</td>\n",
       "      <td>654.25</td>\n",
       "      <td>891.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>7.445719</td>\n",
       "      <td>1.477129</td>\n",
       "      <td>2.583333</td>\n",
       "      <td>7.733300</td>\n",
       "      <td>7.750000</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>15.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>353.0</td>\n",
       "      <td>440.685552</td>\n",
       "      <td>263.352933</td>\n",
       "      <td>1.0</td>\n",
       "      <td>201.00</td>\n",
       "      <td>432.0</td>\n",
       "      <td>668.00</td>\n",
       "      <td>889.0</td>\n",
       "      <td>353.0</td>\n",
       "      <td>0.189802</td>\n",
       "      <td>...</td>\n",
       "      <td>3.00</td>\n",
       "      <td>11.0</td>\n",
       "      <td>353.0</td>\n",
       "      <td>7.178502</td>\n",
       "      <td>2.026679</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.322727</td>\n",
       "      <td>7.795800</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>22.52500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9 rows × 96 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                PassengerId                                                \\\n",
       "                      count        mean         std    min     25%    50%   \n",
       "Pclass Embarked                                                             \n",
       "1      0               87.0  440.919540  243.405644    2.0  266.50  453.0   \n",
       "       1                2.0  329.500000  118.086832  246.0  287.75  329.5   \n",
       "       2              127.0  477.842520  249.989537    4.0  273.50  493.0   \n",
       "2      0               17.0  444.352941  297.394507   10.0  182.00  390.0   \n",
       "       1                3.0  418.000000  181.248448  304.0  313.50  323.0   \n",
       "       2              164.0  446.634146  248.088942   16.0  234.50  439.0   \n",
       "3      0               66.0  451.484848  277.967305   20.0  205.00  483.0   \n",
       "       1               72.0  420.347222  259.844545    6.0  198.50  400.5   \n",
       "       2              353.0  440.685552  263.352933    1.0  201.00  432.0   \n",
       "\n",
       "                               Survived            ... Group_count        \\\n",
       "                    75%    max    count      mean  ...         75%   max   \n",
       "Pclass Embarked                                    ...                     \n",
       "1      0         637.50  890.0     87.0  0.701149  ...        3.00   5.0   \n",
       "       1         371.25  413.0      2.0  0.500000  ...        2.75   3.0   \n",
       "       2         698.50  888.0    127.0  0.582677  ...        3.00   6.0   \n",
       "2      0         686.00  875.0     17.0  0.529412  ...        3.00   4.0   \n",
       "       1         475.00  627.0      3.0  0.666667  ...        1.00   1.0   \n",
       "       2         668.00  887.0    164.0  0.463415  ...        3.00   6.0   \n",
       "3      0         693.50  876.0     66.0  0.378788  ...        2.00   4.0   \n",
       "       1         654.25  891.0     72.0  0.375000  ...        2.00   6.0   \n",
       "       2         668.00  889.0    353.0  0.189802  ...        3.00  11.0   \n",
       "\n",
       "                Fare_ind                                              \\\n",
       "                   count       mean        std        min        25%   \n",
       "Pclass Embarked                                                        \n",
       "1      0            87.0  45.409578  30.259151  14.850000  28.588550   \n",
       "       1             2.0  37.500000  10.606602  30.000000  33.750000   \n",
       "       2           127.0  32.944412  21.158412   0.000000  26.282300   \n",
       "2      0            17.0  12.549366   2.185885   6.929150  12.000000   \n",
       "       1             3.0  12.350000   0.000000  12.350000  12.350000   \n",
       "       2           164.0  11.004243   3.675578   0.000000   9.750000   \n",
       "3      0            66.0   6.717735   1.384601   2.409733   5.825012   \n",
       "       1            72.0   7.445719   1.477129   2.583333   7.733300   \n",
       "       2           353.0   7.178502   2.026679   0.000000   6.322727   \n",
       "\n",
       "                                                \n",
       "                       50%      75%        max  \n",
       "Pclass Embarked                                 \n",
       "1      0         37.758333  49.5042  170.77640  \n",
       "       1         37.500000  41.2500   45.00000  \n",
       "       2         28.500000  37.8875  221.77920  \n",
       "2      0         12.334733  13.8625   15.05000  \n",
       "       1         12.350000  12.3500   12.35000  \n",
       "       2         12.587500  13.0000   26.00000  \n",
       "3      0          7.227100   7.2292    9.39375  \n",
       "       1          7.750000   7.7500   15.50000  \n",
       "       2          7.795800   8.0500   22.52500  \n",
       "\n",
       "[9 rows x 96 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.groupby(['Pclass','Embarked']).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Age 변수 결측치 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.029340</td>\n",
       "      <td>-0.035349</td>\n",
       "      <td>0.036847</td>\n",
       "      <td>-0.082398</td>\n",
       "      <td>-0.011617</td>\n",
       "      <td>0.009592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>0.029340</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.359653</td>\n",
       "      <td>-0.077221</td>\n",
       "      <td>-0.017358</td>\n",
       "      <td>0.093317</td>\n",
       "      <td>0.268189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <td>-0.035349</td>\n",
       "      <td>-0.359653</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.369226</td>\n",
       "      <td>0.067247</td>\n",
       "      <td>0.025683</td>\n",
       "      <td>-0.554182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>0.036847</td>\n",
       "      <td>-0.077221</td>\n",
       "      <td>-0.369226</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.308247</td>\n",
       "      <td>-0.189119</td>\n",
       "      <td>0.096067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp</th>\n",
       "      <td>-0.082398</td>\n",
       "      <td>-0.017358</td>\n",
       "      <td>0.067247</td>\n",
       "      <td>-0.308247</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.383820</td>\n",
       "      <td>0.138329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parch</th>\n",
       "      <td>-0.011617</td>\n",
       "      <td>0.093317</td>\n",
       "      <td>0.025683</td>\n",
       "      <td>-0.189119</td>\n",
       "      <td>0.383820</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.205119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare</th>\n",
       "      <td>0.009592</td>\n",
       "      <td>0.268189</td>\n",
       "      <td>-0.554182</td>\n",
       "      <td>0.096067</td>\n",
       "      <td>0.138329</td>\n",
       "      <td>0.205119</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             PassengerId  Survived    Pclass       Age     SibSp     Parch  \\\n",
       "PassengerId     1.000000  0.029340 -0.035349  0.036847 -0.082398 -0.011617   \n",
       "Survived        0.029340  1.000000 -0.359653 -0.077221 -0.017358  0.093317   \n",
       "Pclass         -0.035349 -0.359653  1.000000 -0.369226  0.067247  0.025683   \n",
       "Age             0.036847 -0.077221 -0.369226  1.000000 -0.308247 -0.189119   \n",
       "SibSp          -0.082398 -0.017358  0.067247 -0.308247  1.000000  0.383820   \n",
       "Parch          -0.011617  0.093317  0.025683 -0.189119  0.383820  1.000000   \n",
       "Fare            0.009592  0.268189 -0.554182  0.096067  0.138329  0.205119   \n",
       "\n",
       "                 Fare  \n",
       "PassengerId  0.009592  \n",
       "Survived     0.268189  \n",
       "Pclass      -0.554182  \n",
       "Age          0.096067  \n",
       "SibSp        0.138329  \n",
       "Parch        0.205119  \n",
       "Fare         1.000000  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Age 결측치 처리를 위해 다른 컬럼에서 Age를 예측하도록 해볼까?\n",
    "# 어떤 변수가 Age와 연관성이 높은지 보자\n",
    "train[~train['Age'].isnull()].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_train = train[~train['Age'].isnull()]\n",
    "age_test = train[train['Age'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_X = age_train.drop(['PassengerId','Age','Name','Sex','Ticket'],axis=1)\n",
    "age_y = age_train.Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Survived', 'Pclass', 'Name', 'Sex', 'SibSp', 'Parch', 'Ticket', 'Fare',\n",
       "       'Cabin', 'Embarked'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielhan/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:528: FutureWarning: From version 0.22, errors during fit will result in a cross validation score of NaN by default. Use error_score='raise' if you want an exception raised or error_score=np.nan to adopt the behavior from version 0.22.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "DataFrame.dtypes for data must be int, float or bool.\n                Did not expect the data types in fields Name, Sex, Ticket, Cabin, Embarked",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-648634f12f9d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m         }\n\u001b[1;32m     10\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxgr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mage_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mage_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    685\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1466\u001b[0m         evaluate_candidates(ParameterSampler(\n\u001b[1;32m   1467\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1468\u001b[0;31m             random_state=self.random_state))\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    664\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 666\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    667\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    512\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 514\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[1;32m    340\u001b[0m                                    missing=self.missing, nthread=self.n_jobs)\n\u001b[1;32m    341\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m             \u001b[0mtrainDmatrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnthread\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0mevals_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, label, missing, weight, silent, feature_names, feature_types, nthread)\u001b[0m\n\u001b[1;32m    382\u001b[0m         data, feature_names, feature_types = _maybe_pandas_data(data,\n\u001b[1;32m    383\u001b[0m                                                                 \u001b[0mfeature_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m                                                                 feature_types)\n\u001b[0m\u001b[1;32m    385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         data, feature_names, feature_types = _maybe_dt_data(data,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36m_maybe_pandas_data\u001b[0;34m(data, feature_names, feature_types)\u001b[0m\n\u001b[1;32m    239\u001b[0m         msg = \"\"\"DataFrame.dtypes for data must be int, float or bool.\n\u001b[1;32m    240\u001b[0m                 Did not expect the data types in fields \"\"\"\n\u001b[0;32m--> 241\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbad_fields\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfeature_names\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: DataFrame.dtypes for data must be int, float or bool.\n                Did not expect the data types in fields Name, Sex, Ticket, Cabin, Embarked"
     ]
    }
   ],
   "source": [
    "xgr = xgb.XGBRegressor(random_seed=0,n_estimators=400)\n",
    "parameters = {\n",
    "        'min_child_weight': [1, 5, 10],\n",
    "        'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "        'max_depth': [3, 4, 5],\n",
    "        'learning_rate': [0.0001, 0.001, 0.01, 0.1]\n",
    "        }\n",
    "clf = RandomizedSearchCV(xgr, parameters,n_iter=100, cv=5)\n",
    "clf.fit(age_X, age_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA20AAAEyCAYAAABptTjBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAG2lJREFUeJzt3X+QXedZH/DvY68V5ICSgkSHxjIOU0OzYSDBmjQ0yA0kbZ2U2J3BVPaUljIp/ocUaNJ2QlsZmg7TATqF/khJMiGFMiV2sMG2FNeCCWFoMkiN5IAcR/ZUMkhxJbAMkWitATnt0z/22iybu6tj62rvsffzmdnRPee++57nPPecc/ere+9udXcAAAAYp8vmXQAAAACrE9oAAABGTGgDAAAYMaENAABgxIQ2AACAERPaAAAARkxoAwAAGDGhDQAAYMSENgAAgBFbmNeGt27d2tdcc828Ng8AADBXhw4derK7t11o3NxC2zXXXJODBw/Oa/MAAABzVVXHh4zz9kgAAIARE9oAAABGTGgDAAAYMaENAABgxIQ2AACAERPaAAAARkxoAwAAGLELhraq+lBVPVFVn1nl/qqqf19VR6vqcFV90+zLBAAA2JiGvNL2s0luWOP+tyS5dvJ1W5KfvviyAAAASAaEtu7+jSR/uMaQm5L8l16yP8nLq+qrZlXgenr66aezd+/ePP300zl79mxuvvnmvOtd78r73//+LC4u5tSpU6t+79mzZ3PLLbfk7Nmza27j1KlTefWrX73mXMeOHcu2bdty7NixNed68sknc/311+fJJ59cdcy5c+dy++2359y5c2vOtXzf1zJkvqHbHGJoXUPGDa1r6GM5pP8nTpzI1VdfnRMnTqw515BxDz30UK688so89NBDa841ZNwsj9cDBw7kiiuuyIEDBy56riTZt29fqir79u1bdcws+zq0/iHn5SOPPJKXvexleeSRR77ovhtvvDFVlRtvvDEPPvhgXvKSl+TBBx9cc5trzfeMaY/3tPNhSC+G9nVIz4b2dci5O/TYGTpuyH4OvV4MmWvodWzIeTl0H4cYWtfQ42LINXFo/UP6P/Q6NmQ/ZznX0PqHGlrbELOsa71/HoCLMfTcHbXuvuBXkmuSfGaV+/Ym+ZZlyx9LsmOVsbclOZjk4NVXX91js2fPnt60aVPv2bOnd+3a1Un+zNfi4uKq3/vM+F27dq25jcXFxQvOtXXr1k7SW7duXXOunTt3dpLeuXPnqmN2797dSXr37t1rzrV839cyZL6h2xxiaF1Dxg2ta+hjOaT/27dv7yS9ffv2NecaMm7z5s2dpDdv3rzmXEPGzfJ4XVhY6CS9sLBw0XN1958551Yzy74OrX/Ieblly5ZO0lu2bPmi+5bv16ZNm579dy1rzfeMaY/3tPNhSC+G9nVIz4b2dci5O/TYGTpuyH4OvV4MmWvodWzIeTl0H4cYWtfQ42LINXFo/UP6P/Q6NmQ/ZznX0PqHGlrbELOsa71/HoCLMfTcnYckB3tIHhs0aO3Q9tEpoe26C8153XXXXfImPFfnz5/vPXv29Pnz5/vMmTP9Hd/xHf3Od76z3/e+9/WrXvWqPnny5Krfe+bMmd61a1efOXNmzW2cPHmyFxcX15zr6NGjvXXr1j569Oiac50+fbp37tzZp0+fXnXMU0891bt37+6nnnpqzbmW7/tahsw3dJtDDK1ryLihdQ19LIf0//jx4719+/Y+fvz4mnMNGXf48OHevHlzHz58eM25hoyb5fG6f//+XlhY6P3791/0XN3dDzzwQCfpBx54YNUxs+zr0PqHnJdHjhzpLVu29JEjR77ovre97W2dpN/2trf1oUOHetOmTX3o0KE1t7nWfM+Y9nhPOx+G9GJoX4f0bGhfh5y7Q4+doeOG7OfQ68WQuYZex4acl0P3cYihdQ09LoZcE4fWP6T/Q69jQ/ZzlnMNrX+oobUNMcu61vvnAbgYQ8/deRga2mpp7Nqq6poke7v766fc9/4kv97dH54sP5rkjd295nsfduzY0QcPHrzgtgEAAF6MqupQd++40LhZ/Mr/+5L8vclvkXx9krMXCmwAAAAMs3ChAVX14SRvTLK1qh5P8sNJrkiS7n5fkvuTvDXJ0STnknzPpSoWAABgo7lgaOvuWy9wfyf5vplVBAAAwLNm8fZIAAAALhGhDQAAYMSENgAAgBET2gAAAEZMaAMAABgxoQ0AAGDEhDYAAIARE9oAAABGTGgDAAAYMaENAABgxIQ2AACAERPaAAAARkxoAwAAGDGhDQAAYMSENgAAgBET2gAAAEZMaAMAABgxoQ0AAGDEhDYAAIARE9oAAABGTGgDAAAYMaENAABgxIQ2AACAERPaAAAARkxoAwAAGDGhDQAAYMSENgAAgBET2gAAAEZMaAMAABgxoQ0AAGDEhDYAAIARE9oAAABGTGgDAAAYMaENAABgxIQ2AACAERPaAAAARkxoAwAAGDGhDQAAYMSENgAAgBET2gAAAEZsUGirqhuq6tGqOlpV755y/9VV9fGq+nRVHa6qt86+VAAAgI3ngqGtqi5P8t4kb0mymOTWqlpcMexfJPlId782yS1J/tOsCwUAANiIhrzS9rokR7v7se4+n+SOJDetGNNJtkxuvyzJydmVCAAAsHEtDBjziiSfW7b8eJK/vGLMjyT5lar6h0lemuTNM6kOAABggxvySltNWdcrlm9N8rPdfVWStyb5+ar6ormr6raqOlhVB0+fPv3cqwUAANhghoS2x5NsX7Z8Vb747Y9vT/KRJOnu30zyJUm2rpyouz/Q3Tu6e8e2bdueX8UAAAAbyJDQ9qkk11bVK6tqU5Z+0ch9K8acSPKmJKmqV2UptHkpDQAA4CJdMLR19xeSvCPJviRHsvRbIh+uqvdU1Y2TYe9K8r1V9dtJPpzk73f3yrdQAgAA8BwN+UUk6e77k9y/Yt3ty25/NskbZlsaAAAAg/64NgAAAPMhtAEAAIyY0AYAADBiQhsAAMCICW0AAAAjJrQBAACMmNAGAAAwYkIbAADAiAltAAAAIya0AQAAjJjQBgAAMGJCGwAAwIgJbQAAACMmtAEAAIyY0AYAADBiQhsAAMCICW0AAAAjJrQBAACMmNAGAAAwYkIbAADAiAltAAAAIya0AQAAjJjQBgAAMGJCGwAAwIgJbQAAACMmtAEAAIyY0AYAADBiQhsAAMCICW0AAAAjJrQBAACMmNAGAAAwYkIbAADAiAltAAAAIya0AQAAjJjQBgAAMGJCGwAAwIgJbQAAACMmtAEAAIyY0AYAADBiQhsAAMCICW0AAAAjNii0VdUNVfVoVR2tqnevMuZvV9Vnq+rhqvqF2ZYJAACwMS1caEBVXZ7kvUn+WpLHk3yqqu7r7s8uG3Ntkh9K8obu/nxVfeWlKhgAAGAjGfJK2+uSHO3ux7r7fJI7kty0Ysz3Jnlvd38+Sbr7idmWCQAAsDENCW2vSPK5ZcuPT9Yt97VJvraqPllV+6vqhmkTVdVtVXWwqg6ePn36+VUMAACwgQwJbTVlXa9YXkhybZI3Jrk1yQer6uVf9E3dH+juHd29Y9u2bc+1VgAAgA1nSGh7PMn2ZctXJTk5Zcy93f10d/9OkkezFOIAAAC4CENC26eSXFtVr6yqTUluSXLfijH3JPnWJKmqrVl6u+RjsywUAABgI7pgaOvuLyR5R5J9SY4k+Uh3P1xV76mqGyfD9iX5g6r6bJKPJ/kn3f0Hl6poAACAjaK6V348bX3s2LGjDx48OJdtAwAAzFtVHeruHRcaN+iPawMAADAfQhsAAMCICW0AAAAjJrQBAACMmNAGAAAwYkIbAADAiAltAAAAIya0AQAAjJjQBgAAMGJCGwAAwIgJbQAAACMmtAEAAIyY0AYAADBiQhsAAMCICW0AAAAjJrQBAACMmNAGAAAwYkIbAADAiAltAAAAIya0AQAAjJjQBgAAMGJCGwAAwIgJbQAAACMmtAEAAIyY0AYAADBiQhsAAMCICW0AAAAjJrQBAACMmNAGAAAwYkIbAADAiAltAAAAIya0AQAAjJjQBgAAMGJCGwAAwIgJbQAAACMmtAEAAIyY0AYAADBiQhsAAMCICW0AAAAjJrQBAACM2KDQVlU3VNWjVXW0qt69xribq6qrasfsSgQAANi4LhjaquryJO9N8pYki0lurarFKeO+LMn3Jzkw6yIBAAA2qiGvtL0uydHufqy7zye5I8lNU8b9qyQ/nuSPZ1gfAADAhjYktL0iyeeWLT8+Wfesqnptku3dvXeGtQEAAGx4Q0JbTVnXz95ZdVmSn0zyrgtOVHVbVR2sqoOnT58eXiUAAMAGNSS0PZ5k+7Llq5KcXLb8ZUm+PsmvV9XvJnl9kvum/TKS7v5Ad+/o7h3btm17/lUDAABsEENC26eSXFtVr6yqTUluSXLfM3d299nu3trd13T3NUn2J7mxuw9ekooBAAA2kAuGtu7+QpJ3JNmX5EiSj3T3w1X1nqq68VIXCAAAsJEtDBnU3fcnuX/FuttXGfvGiy8LAACAZOAf1wYAAGA+hDYAAIARE9oAAABGTGgDAAAYMaENAABgxIQ2AACAERPaAAAARkxoAwAAGDGhDQAAYMSENgAAgBET2gAAAEZMaAMAABgxoQ0AAGDEhDYAAIARE9oAAABGTGgDAAAYMaENAABgxIQ2AACAERPaAAAARkxoAwAAGDGhDQAAYMSENgAAgBET2gAAAEZMaAMAABgxoQ0AAGDEhDYAAIARE9oAAABGTGgDAAAYMaENAABgxIQ2AACAERPaAAAARkxoAwAAGDGhDQAAYMSENgAAgBET2gAAAEZMaAMAABgxoQ0AAGDEhDYAAIARE9oAAABGTGgDAAAYMaENAABgxAaFtqq6oaoeraqjVfXuKfe/s6o+W1WHq+pjVfXVsy8VAABg47lgaKuqy5O8N8lbkiwmubWqFlcM+3SSHd39DUnuSvLjsy4UAABgIxryStvrkhzt7se6+3ySO5LctHxAd3+8u89NFvcnuWq2ZQIAAGxMQ0LbK5J8btny45N1q3l7kv827Y6quq2qDlbVwdOnTw+vEgAAYIMaEtpqyrqeOrDqu5LsSPIT0+7v7g90947u3rFt27bhVQIAAGxQCwPGPJ5k+7Llq5KcXDmoqt6c5J8n+avd/SezKQ8AAGBjG/JK26eSXFtVr6yqTUluSXLf8gFV9dok709yY3c/MfsyAQAANqYLhrbu/kKSdyTZl+RIko9098NV9Z6qunEy7CeSfGmSX6yq36qq+1aZDgAAgOdgyNsj0933J7l/xbrbl91+84zrAgAAIAP/uDYAAADzIbQBAACMmNAGAAAwYkIbAADAiAltAAAAIya0AQAAjJjQBgAAMGJCGwAAwIgJbQAAACMmtAEAAIyY0AYAADBiQhsAAMCICW0AAAAjJrQBAACMmNAGAAAwYkIbAADAiAltAAAAIya0AQAAjJjQBgAAMGJCGwAAwIgJbQAAACMmtAEAAIyY0AYAADBiQhsAAMCICW0AAAAjJrQBAACMmNAGAAAwYkIbAADAiAltAAAAIya0AQAAjJjQBgAAMGJCGwAAwIgJbQAAACMmtAEAAIyY0AYAADBiQhsAAMCICW0AAAAjJrQBAACMmNAGAAAwYkIbAADAiA0KbVV1Q1U9WlVHq+rdU+5/SVXdObn/QFVdM+tCAQAANqILhraqujzJe5O8JclikluranHFsLcn+Xx3/8UkP5nkx2ZdKAAAwEY05JW21yU52t2Pdff5JHckuWnFmJuS/Nzk9l1J3lRVNbsy5+vcuXO5/fbbc+7cuVXHHDt2LNu2bcuxY8fWnOvpp5/O3r178/TTT6865uzZs7nlllty9uzZ513zc9leMmwfh447ceJErr766pw4ceKi55plL4aats1pfRzS2wMHDuSKK67IgQMH1tzmkOPn3nvvTVXl3nvvXXOuj370o6mqfPSjH111zCc/+clcfvnl+eQnP/nsumn7c+edd6aqcuedd17U9pLkwQcfzEte8pI8+OCDa25z3759qars27dv1TFDezFtP1caeu7efffdqarcfffdz65beQyvtb2qevZr5T5OmytJHnrooVx55ZV56KGHVq1r2phpPZvlXEN6Nu3YnzbXqVOn8upXvzqnTp1ada6h15Qh+zit/mm9f/LJJ3P99dfnySeffE5zTTN0riH7OW170+ofcu185JFH8rKXvSyPPPLImnUNvQ4PuaYPebyHjpvl88PQuoY+FwzpxSyfd2c51ywf76GGzjWktqE/96y3afv4fI+dWRtrz1ihu9f8SnJzkg8uW/67Sf7jijGfSXLVsuVjSbZOmeu2JAeTHLz66qv7hWL37t2dpHfv3r3qmK1bt3aS3rp165pz7dmzpzdt2tR79uxZdcyuXbs6Se/atet51/xcttc9bB+Hjtu+fXsn6e3bt1/0XLPsxVDTtjmtj0N6u7Cw0El6YWFhzW0OOX6SPPu1liHjLrvssk7Sl1122bPrpu3PkLmG1rVp06ZO0ps2bXpO23y+da22nysNPXenbXPlMbzW9pZ//5C5urs3b97cSXrz5s2r1jVtzLSezXKuIT2bduxPm2txcbGT9OLi4qpzDb2mDNnHafVP6/3OnTs7Se/cufM5zTXN0LmG7Oe07U2rf8i1c8uWLZ2kt2zZsmZdQ6/DQ67pQx7voeNm+fwwtK6hzwVDejHL591ZzjXLx3uooXMNqW3ozz3rbdo+Pt9jZ9bG2rONIsnBvkAe6+5Boe07p4S2/7BizMNTQttXrDXvddddtw5tmI2nnnqqd+/e3U899dSqY44ePdpbt27to0ePrjnX+fPne8+ePX3+/PlVx5w5c6Z37drVZ86ced41P5ftdQ/bx6Hjjh8/3tu3b+/jx49f9Fyz7MVQ07Y5rY9Dert///5eWFjo/fv3r7nNIcfPPffc00n6nnvuWXOuvXv3dpLeu3fvqmM+8YlP9GWXXdaf+MQnnl03bX/uuOOOTtJ33HHHRW2vu/vQoUO9adOmPnTo0JrbfOCBBzpJP/DAA6uOGdqLafu50tBz96677uokfddddz27buUxvNb2lge1lfs4ba7u7sOHD/fmzZv78OHDq9Y1bcy0ns1yriE9m3bsT5vr5MmTvbi42CdPnlx1rqHXlCH7OK3+ab0/ffp079y5s0+fPv2c5ppm6FxD9nPa9qbVP+TaeeTIkd6yZUsfOXJkzbqGXoeHXNOHPN5Dx83y+WFoXUOfC4b0YpbPu7Oca5aP91BD5xpS29Cfe9bbtH18vsfOrI21ZxvF0NBWS2NXV1XfnORHuvtvTJZ/KEv/Pfyvl43ZNxnzm1W1kOT3kmzrNSbfsWNHHzx4cM1tAwAAvFhV1aHu3nGhcUM+0/apJNdW1SuralOSW5Lct2LMfUm+e3L75iS/tlZgAwAAYJiFCw3o7i9U1TuS7EtyeZIPdffDVfWeLL2cd1+Sn0ny81V1NMkfZinYAQAAcJEuGNqSpLvvT3L/inW3L7v9x1n67BsAAAAzNOiPawMAADAfQhsAAMCICW0AAAAjJrQBAACMmNAGAAAwYkIbAADAiAltAAAAI1bdPZ8NV51OcnwuG/+ztiZ5ct5FbGD6Pz96P1/6P1/6Pz96P1/6Pz96P19j7f9Xd/e2Cw2aW2gbi6o62N075l3HRqX/86P386X/86X/86P386X/86P38/VC77+3RwIAAIyY0AYAADBiQlvygXkXsMHp//zo/Xzp/3zp//zo/Xzp//zo/Xy9oPu/4T/TBgAAMGZeaQMAABgxoQ0AAGDENnRoq6obqurRqjpaVe+edz0vdlX1oap6oqo+s2zdl1fVr1bV/5z8++fmWeOLVVVtr6qPV9WRqnq4qn5gsl7/L7Gq+pKq+h9V9duT3v/LyfpXVtWBSe/vrKpN8671xayqLq+qT1fV3smy/q+Tqvrdqnqoqn6rqg5O1rn2rIOqenlV3VVVj0yu/9+s9+ujqr5ucsw/8/VHVfWD+r8+quofTZ5zP1NVH548F7+gr/sbNrRV1eVJ3pvkLUkWk9xaVYvzrepF72eT3LBi3buTfKy7r03ysckys/eFJO/q7lcleX2S75sc7/p/6f1Jkm/r7m9M8pokN1TV65P8WJKfnPT+80nePscaN4IfSHJk2bL+r69v7e7XLPsbSa496+PfJXmgu/9Skm/M0jmg9+ugux+dHPOvSXJdknNJfjn6f8lV1SuSfH+SHd399UkuT3JLXuDX/Q0b2pK8LsnR7n6su88nuSPJTXOu6UWtu38jyR+uWH1Tkp+b3P65JH9rXYvaILr7VHc/OLn9v7P0xP2K6P8l10v+z2TxislXJ/m2JHdN1uv9JVRVVyX5m0k+OFmu6P+8ufZcYlW1Jcn1SX4mSbr7fHefid7Pw5uSHOvu49H/9bKQZHNVLSS5MsmpvMCv+xs5tL0iyeeWLT8+Wcf6+vPdfSpZChZJvnLO9bzoVdU1SV6b5ED0f11M3pr3W0meSPKrSY4lOdPdX5gMcf25tH4qyT9N8v8my18R/V9PneRXqupQVd02Wefac+l9TZLTSf7z5K3BH6yql0bv5+GWJB+e3Nb/S6y7/1eSf5PkRJbC2tkkh/ICv+5v5NBWU9b5+we8qFXVlya5O8kPdvcfzbuejaK7/+/kLTJXZelV/ldNG7a+VW0MVfXtSZ7o7kPLV08Zqv+Xzhu6+5uy9HGE76uq6+dd0AaxkOSbkvx0d782yVPxVrx1N/nc1I1JfnHetWwUk88J3pTklUn+QpKXZun6s9IL6rq/kUPb40m2L1u+KsnJOdWykf1+VX1Vkkz+fWLO9bxoVdUVWQps/7W7f2myWv/X0eStSb+epc8Vvnzyto3E9edSekOSG6vqd7P0Nvhvy9Irb/q/Trr75OTfJ7L0mZ7XxbVnPTye5PHuPjBZvitLIU7v19dbkjzY3b8/Wdb/S+/NSX6nu09399NJfinJX8kL/Lq/kUPbp5JcO/lNMpuy9NL1fXOuaSO6L8l3T25/d5J751jLi9bkMzw/k+RId//bZXfp/yVWVduq6uWT25uz9GRyJMnHk9w8Gab3l0h3/1B3X9Xd12TpOv9r3f13ov/roqpeWlVf9sztJH89yWfi2nPJdffvJflcVX3dZNWbknw2er/ebs2fvjUy0f/1cCLJ66vqysnPP88c+y/o6351v6BeGZypqnprlv7H9fIkH+ruH51zSS9qVfXhJG9MsjXJ7yf54ST3JPlIkquzdJJ9Z3ev/GUlXKSq+pYk/z3JQ/nTz/X8syx9rk3/L6Gq+oYsfeD58iz9R9lHuvs9VfU1WXrl58uTfDrJd3X3n8yv0he/qnpjkn/c3d+u/+tj0udfniwuJPmF7v7RqvqKuPZcclX1miz9Ap5NSR5L8j2ZXIei95dcVV2Zpd+f8DXdfXayzrG/DiZ/XmdXln579qeT/IMsfYbtBXvd39ChDQAAYOw28tsjAQAARk9oAwAAGDGhDQAAYMSENgAAgBET2gAAAEZMaAMAABgxoQ0AAGDE/j+skwEMGr/4dwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(df_train.Age, df_train.Survived,'o',color='black',markersize=0.7)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

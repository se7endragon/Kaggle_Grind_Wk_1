{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Model\n",
    "## 변수 처리 방법\n",
    "- Passenger ID : 제거\n",
    "- Pclass : Ordinal 변수이므로 그대로 채용.\n",
    "- Sex : Label-Encode\n",
    "- Age : 그대로 (Mean으로 결측값 Impute)\n",
    "- Sibsp, Parch : 그대로\n",
    "- Ticket : 제거\n",
    "- Fare : 그대로, 단 Ticket변수와 Sibsp+parch 사용하여 그룹멤버들만큼 나눠서 1인당 요금으로 계산\n",
    "- Cabin : Binary로 변환\n",
    "- Embarked : one-hot encoding with NaN imputed as 'C'. (NaN승객들과 같은 Pclass 승객들의 Fare mean으로 C인것을 유추)\n",
    "\n",
    "## 생성변수\n",
    "- Group : Ticket 변수가 unique하지 않거나 Sibsp+parch > 0 일때 1, 아닐때 0을 가지는 단체승객여부 변수."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dataset\n",
    "df_train = pd.read_csv(\"train.csv\")\n",
    "df_test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "#결측치 처리 (Age, Embarked)\n",
    "df_train['Age'].fillna(df_train['Age'].mean(),inplace=True)\n",
    "df_test['Age'].fillna(df_train['Age'].mean(),inplace=True)\n",
    "df_train['Embarked'].fillna('C',inplace=True)\n",
    "\n",
    "#Cabin 결측치 처리 겸 변수 변환\n",
    "df_train['Cabin'] = df_train.Cabin.apply(lambda x: 1 if pd.notnull(x) else 0)\n",
    "df_test['Cabin'] = df_test.Cabin.apply(lambda x: 1 if pd.notnull(x) else 0)\n",
    "\n",
    "#Group 변수 생성\n",
    "#Family size랑 dup_count 중 큰걸로 fare 나누기.\n",
    "df_train['Family_size'] = df_train['SibSp']+df_train['Parch']+1\n",
    "df_train['dup_count'] = df_train.groupby(['Ticket'])['Ticket'].transform('count')\n",
    "df_train['Group'] = ~((df_train['Family_size'] == 1) & (df_train['dup_count'] == 1))\n",
    "df_train['Group_count'] = df_train[['Family_size','dup_count']].max(axis=1)\n",
    "df_train['Fare_ind'] = df_train['Fare']/df_train['Group_count']\n",
    "\n",
    "#Fare 결측치 처리 in test\n",
    "df_test['Fare'].fillna(df_test['Fare'].mean(),inplace=True)\n",
    "\n",
    "df_test['Family_size'] = df_test['SibSp']+df_test['Parch']+1\n",
    "df_test['dup_count'] = df_test.groupby(['Ticket'])['Ticket'].transform('count')\n",
    "df_test['Group'] = ~((df_test['Family_size'] == 1) & (df_test['dup_count'] == 1))\n",
    "df_test['Group_count'] = df_test[['Family_size','dup_count']].max(axis=1)\n",
    "df_test['Fare_ind'] = df_test['Fare']/df_test['Group_count']\n",
    "\n",
    "# Categorical Feature Encoding\n",
    "df_train['Sex'] = df_train['Sex'].apply(lambda x: 1 if x is 'male' else 0)\n",
    "df_test['Sex'] = df_test['Sex'].apply(lambda x: 1 if x is 'male' else 0)\n",
    "df_train = pd.get_dummies(df_train, columns = ['Embarked'],drop_first=True,prefix='', prefix_sep='')\n",
    "df_test = pd.get_dummies(df_test, columns = ['Embarked'],drop_first=True,prefix='', prefix_sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델에 사용하지 않을 변수 제거\n",
    "train_X = df_train.drop(['PassengerId','Survived','Name','Ticket','Fare','Cabin','Family_size','dup_count','Group_count'],axis=1)\n",
    "test_X = df_test.drop(['PassengerId','Name','Ticket','Fare','Cabin','Family_size','dup_count','Group_count'],axis=1)\n",
    "train_y = df_train.Survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielhan/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "                   estimator=RandomForestClassifier(bootstrap=True,\n",
       "                                                    class_weight=None,\n",
       "                                                    criterion='gini',\n",
       "                                                    max_depth=None,\n",
       "                                                    max_features='auto',\n",
       "                                                    max_leaf_nodes=None,\n",
       "                                                    min_impurity_decrease=0.0,\n",
       "                                                    min_impurity_split=None,\n",
       "                                                    min_samples_leaf=1,\n",
       "                                                    min_samples_split=2,\n",
       "                                                    min_weight_fraction_leaf=0.0,\n",
       "                                                    n_estimators='warn',\n",
       "                                                    n_jobs=None,\n",
       "                                                    oob_score=False,\n",
       "                                                    random_state=0, verbose=0,\n",
       "                                                    warm_start=False),\n",
       "                   iid='warn', n_iter=100, n_jobs=None,\n",
       "                   param_distributions={'max_depth': [80, 90, 100, 110],\n",
       "                                        'max_features': [2, 3],\n",
       "                                        'min_samples_leaf': [3, 4, 5],\n",
       "                                        'min_samples_split': [8, 10, 12],\n",
       "                                        'n_estimators': [100, 200, 300]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=0)\n",
    "parameters = {'max_depth': [80, 90, 100, 110],\n",
    "    'max_features': [2, 3],\n",
    "    'min_samples_leaf': [3, 4, 5],\n",
    "    'min_samples_split': [8, 10, 12],\n",
    "    'n_estimators': [100, 200, 300]}\n",
    "clf = RandomizedSearchCV(rf, parameters,n_iter = 100, cv=5)\n",
    "clf.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 100,\n",
       " 'min_samples_split': 10,\n",
       " 'min_samples_leaf': 5,\n",
       " 'max_features': 2,\n",
       " 'max_depth': 80}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7283950617283951"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
